%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% I, the copyright holder of this work, release this work into the
%% public domain. This applies worldwide. In some countries this may
%% not be legally possible; if so: I grant anyone the right to use
%% this work for any purpose, without any conditions, unless such
%% conditions are required by law.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[
  digital, %% This option enables the default options for the
           %% digital version of a document. Replace with `printed`
           %% to enable the default options for the printed version
           %% of a document.
  table,   %% Causes the coloring of tables. Replace with `notable`
           %% to restore plain tables.
  nolof,     %% Prints the List of Figures. Replace with `nolof` to
           %% hide the List of Figures.
  nolot,     %% Prints the List of Tables. Replace with `nolot` to
           %% hide the List of Tables.
  oneside, %% or twoside
  nocover,
  monochrome,
  12pt
  %% More options are listed in the user guide at
  %% <http://mirrors.ctan.org/macros/latex/contrib/fithesis/guide/mu/fi.pdf>.
]{fithesis3}
%% The following section sets up the locales used in the thesis.


\usepackage[many]{tcolorbox}
\tcbuselibrary{listings}

\newtcblisting{mylisting}{
  listing only,
  hbox,
  colframe=gray,
  colback=gray!10,
  listing options={
    basicstyle=\small\ttfamily,
    breaklines=false,
  	frame=none,
    columns=fullflexible
  }
}

\usepackage{caption}
\usepackage{listings}
\usepackage{color}
\usepackage{float}
\usepackage{fancyvrb}

\renewcommand{\lstlistingname}{Ukázka kódu}
\renewcommand{\lstlistlistingname}{Ukázky kódu}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{
  frame=tb,
  language=Java,
  captionpos=b,                    % sets the caption-position to bottom
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[resetfonts]{cmap} %% We need to load the T2A font encoding
\usepackage[T1,T2A]{fontenc}  %% to use the Cyrillic fonts with Russian texts.
\usepackage[
  main=czech, %% By using `czech` or `slovak` as the main locale
                %% instead of `english`, you can typeset the thesis
                %% in either Czech or Slovak, respectively.
  english, german, russian, slovak %% The additional keys allow
]{babel}        %% foreign texts to be typeset as follows:
%%
%%   \begin{otherlanguage}{german}  ... \end{otherlanguage}
%%   \begin{otherlanguage}{russian} ... \end{otherlanguage}
%%   \begin{otherlanguage}{czech}   ... \end{otherlanguage}
%%   \begin{otherlanguage}{slovak}  ... \end{otherlanguage}
%%
%% For non-Latin scripts, it may be necessary to load additional
%% fonts:
\usepackage{paratype}
\def\textrussian#1{{\usefont{T2A}{PTSerif-TLF}{m}{rm}#1}}
%%
%% The following section sets up the metadata of the thesis.
\thesissetup{
    university    = mu,
    faculty       = fi,
    type          = mgr,
    author        = Bc. Tomáš Skopal,
    gender        = m,
    advisor       = RNDr. Filip Nguyen,
    title         = {Distribuované Komplexní Zpracování Událostí},
    TeXtitle      = {Distribuované Komplexní Zpracování Událostí},
    keywords      = {keyword1, keyword2, ...},
    TeXkeywords   = {keyword1, keyword2, \ldots},
    date			 =	2016/05/30
}
\thesislong{abstract}{
    Goal of this thesis is to develop a Peer to Peer algorithm for distributed Event Pattern matching.. The application should be able to run any number of processing nodes. For the needs of this thesis, example of 4 nodes will be sufficient.
}

%% The following section sets up the bibliography.
\usepackage{csquotes}
\usepackage[              %% When typesetting the bibliography, the
  backend=biber,          %% `numeric` style will be used for the
  style=numeric,          %% entries and the `numeric-comp` style
  citestyle=numeric-comp, %% for the references to the entries. The
  sorting=none,           %% entries will be sorted in cite order.
  sortlocale=auto         %% For more unformation about the available
]{biblatex}               %% `style`s and `citestyles`, see:
%% <http://mirrors.ctan.org/macros/latex/contrib/biblatex/doc/biblatex.pdf>.
\addbibresource{example.bib} %% The bibliograpic database within
                          %% the file `example.bib` will be used.
\usepackage{makeidx}      %% The `makeidx` package contains
\makeindex                %% helper commands for index typesetting.
%% These additional packages are used within the document:
\usepackage{paralist}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}
\usepackage{menukeys}
\begin{document}
\chapter{Úvod}

Obecně zadání práce říká, že má být vytvořen middleware pro distribuované zpracování vzorů událostí (angl. middleware solution for distributed event pattern matching). Z anglického popisu vychází zkratka MSFDEPM. Velkým zjednodušením dostaneme "distributed event matching", neboli DEM. Pro účely této práce a snadnější orientaci budu popisované řešení identifikovat zkratkou \textit{DEM}.

\chapter{Zpracování událostí}
Se zvyšujícím se počtem zařízení, která jsou schopna produkovat data, se zvyšuje potřeba tato data analyzovat. Běžně rozšířeným způsobem je zpracování dat dávkově. Tedy, data se uloží a ve vhodnou dobu, typicky v noci, se analyzují.

Pokud však uvažujeme reálný provoz na síti, který se dnes v centrálních uzlech pohybuje okolo $1 Tb/s$ 
%%[https://is.muni.cz/do/rect/habilitace/1433/44368572/44368651/HP_kor.-verejna.pdf]
, je dávkové zpracování nereálné. Potřebujeme data analyzovat za běhu (angl. real time).

Jednotkou zpracování dat je událost (angl. event). Událost je základním pojmem používaným v oblasti zpracování událostí. Je definována jako objekt, který reprezentuje záznam o aktivitě v daném systému. Událost může mít vlastnosti. Typickým příkladem takové vlastnosti je čas vzniku události, příčina jejího vzniku nebo její typ. [\ref{bib_1}] Jednoduchým příkladem události může být paket. Je to datová schránka, která obsahuje informace, které můžeme analyzovat. Samostatný paket nemá téměř žádnou vypovídající hodnotu, kdežto proud paketů je základem Internetu.

Takový proud událostí skrývá množství dat, která je možné získat až při komplexní analýze, která zohledňuje více událostí v řadě. To nazýváme \textit{komplexní zpracování dat (angl. complex event processing neboli CEP)}


\section{CEP}

Je těžké shrnout celý vědní obor pod jednu všeobjímající definici. David Luckham ve své knize  THE POWER OF EVENTS: AN INTRODUCTION TO COMPLEX EVENT PROCESSING IN DISTRIBUTED ENTERPRISE SYSTEMS [\ref{bib_1}] říká, že CEP je soubor technik a nástrojů, které pomáhají k pochopení a kontrole událostmi řízených systémů.

Jak už bylo řečeno, množství událostí v systémech je enormní. Při jejich zpracování se setkáváme s pojmem \textit{komplexní událost}. Taková událost se může vyskytnout pouze jako reakce na sled jiných, dílčích, událostí. Dílčí události mohou spolu souviset mnoha různými způsoby, nejčastěji je však spojujeme na základě vlastností (čas vzniku, příčina vzniku, typ, atd).

Příkladem komplexní události může být akce nakoupení produktu v internetovém obchodě. Je to v dnešní době elektronického marketingu velké téma. Běžnému uživateli Internetu je v mnoha kanálech (Facebook ads, Google ads, mailing) zobrazována reklama. Některý uživatel nakoupí produkt při prvním zobrazení určité reklamy. Jiný uživatel potřebuje reklamu vidět alespoň pětkrát, než nakoupí. Způsob jak tuto "cestu" měřit se jmenuje atribuční model [\ref{bib_6}]. Atribuční model je tak defacto soubor událostí, které vyvolaly konečnou, komplexní, událost. Tedy nákup produktu v obchodě. S roustoucím počtem zařízení, roste počet reklam a také se komplikují atribuční modely. Vhodnými technikami zpracování dílčích událostí (zobrazení reklamy, kliknutí na reklamu, nainstalování aplikace) lze například predikovat chování uživatele.

CEP nabízí techniky pro definici a využití vztahů mezi událostmi. Může být využíván pro analýzu libovolného typu událostí v aplikaci, počítačové síti nebo v informačním systému. Jednou z těchto technik je i definování vlastních událostí, jakožto pravidla. Jinak řečeno, můžeme vytvořit vlastní reakci na soubor určitých událostí v našem systému. Touto cestou můžeme pochopit co se v našem systému odehrává.

To zvyšuje míru flexibility. Uživatel může za pomocí CEP specifikovat taková pravidla, která jej aktuálně zajímají a jsou pro něj přínosem. Může analyzovat jak nízko-úrovňové, tak vysoko-úrovňové procesy. Různé druhy událostí mohou být v CEP monitorovány současně. Velkou výhodou je, že pravidla mohou být měněna, odebírána a přidávána za běhu, tedy bez výpadku systému.

Zpracování proudu událostí a vyhodnocení, jestli se pravidlo vyskytlo, stojí samozřejmě určitý výpočetní výkon. V závislosti na typu a množství dat. Pokud je dat hodně (například analýza síťového provozu), musíme výpočet distribuovat.
 
\section{Distribuované CEP}
Úvodem kapitoly je potřeba jasně vymezit co v tomto kontextu chápeme pod pojmem "distribuovaný". Obecně se používají dva výklady:
\begin{itemize}
  \item Distribuované zpracování událostí jako zpracování událostí z více heterogenních zdrojů (distribuovaný systém).~[\ref{bib_2}] Takový výpočet může běžet i na jenom stroji a samotná analýza většinou nebývá paralelní. Takto pojem používá i \textit{David Luckham} v knize \textit{The Power of Events} [\ref{bib_1}] v popisu obrázku \textit{1.1}.
  \item Distribuované zpracování událostí jako výpočet rozdělený na více menších, méně náročných úloh za účelem rychlejšího zpracování s využitím paralelismu. Dále v práci budeme pojem chápat právě takto.
\end{itemize}

Požadavky na distribuované zpracování událostí (DCEP) jsou v mnoha ohledech jiné než na zpracování centralizované. Dvě hlavní vlastnosti, které vyžadujeme jsou vysoká míra dostupnosti (angl. availability) a nízké zpoždění (angl. latency). Cílem je pak maximalizovat dostupnost a minimalizovat zpoždění. Bohužel u většiny návrhů platí, že tyto vlastnosti jsou závislé a zlepšení jedné, zhoršuje druhou. Zlepšení dostupnosti, zvýší zpoždění, protože potřebujeme více času na synchronizaci všech řídících informací. [\ref{bib_3}]

Zmíněné dvě vlastnosti nejsou jediné. Mezi vlastnosti distribuovaného zpracování události můžeme dále zařadit:
\begin{itemize}
  \item rovnoměrné rozdělení dat mezi výpočetní uzly (angl. data partitioning)
  \item automatické škálování výpočtu
  \item tolerance chyb
  \item správa datového úložiště
\end{itemize}

\chapter{Nástroje pro distribuované zpracování událostí}
\section{Apache Samsa}
\section{Apache Storm}
\section{CAVE}
http://dl.acm.org/citation.cfm?doid=2675743.2771834
\chapter{Analýza}
\label{sec:analysis}

Tato kapitola popisuje požadavky na systém a zasazuje systém do prostředí ve kterém bude nasazen. Počátek kapitoly parafrázuje a rozvíjí zadání práce. Dále je diagram užití, který shrnuje funkční požadavky. Na konci kapitoly jsou na modelovém příkladě demonstrovány vstupy a výstupy systému.

Cílem této práce je vytvoření software pro distribuované zpracování událostí, který bude schopen detekovat komplexní události na základě pravidel. Aplikace by měla být schopna zvládnout libovolný počet připojených uzlů. Síť propojených uzlů je možné reprezentovat grafem G(V, E), kde V jsou uzly grafu, neboli konkrétní počítače na kterých probíhá zpracování. E jsou pak orientované hrany grafu, které reprezentují informaci o tom který počítač posílá data kterému. Každá hrana je označena příznakem \textit{L\_i}, který označuje typ události, která je po dané hraně posílána. Konkrétním příkladem tak může být událost \textit{L\_1}, představující zprávu typu \textit{chyba}, která není tak častá, ale její závažnost je vyšší. A událost \textit{L\_2}, představující zprávu typu \textit{upozornění}, která je častá, ale méně závažná.

Pravidla pro detekci komplexních událostí, budou mít časovou platnost. Po uplynutí daného času se pravidlo automaticky stane neaktivní. Pravidla bude také možné nasadit pouze na určitou podmnožinu uzlů V grafu G. 

Na obrázku \ref{fig:analysis_case_1} je vidět příklad grafu, kde je na uzlu \textit{V1} nasazeno pravidlo analyzující události \textit{L\_1}.

\begin{figure}[H]
	\centering
    \includegraphics[width=0.4\textwidth, height=0.15\textheight]{images/analysis_case_1.png}
    \caption{Před vyhodnocením pravidla \textit{P: L\_1} existuje jeden uzel zpracovávající události}
    \label{fig:analysis_case_1}
\end{figure}

Po určitém počtu výskytů události \textit{L\_1} je vytvořena nová skupina z uzlů V3 a V4 kde je V4 zvolen hlavním uzlem. Viz obr. \ref{fig:analysis_case_2}

\begin{figure}[H]
	\centering
    \includegraphics[width=0.4\textwidth, height=0.15\textheight]{images/analysis_case_2.png}
    \caption{Po vyhodnocení pravidla \textit{P: L\_1} existují dva uzly zpracovávající události}
    \label{fig:analysis_case_2}
\end{figure}

Požadavky jsou kladeny hlavně na variabilitu, možnost nasazení pravidel s časovou platností. Menší důraz je na výkon a proces nasazování.

Na obrázku \ref{fig:usecase} je znázorněn diagram užití, který přehledně shrnuje požadavky na systém. Vystupují v něm dvě role. Uživatel, je zde člověk, který spouští analýzu. Druhou rolí je Algoritmus, který reprezentuje samotný software. Je zde uveden proto, aby bylo zřejmé jaké operace se od systému vyžadují.

\begin{figure}[H]
	\centering
    \includegraphics[width=0.9\textwidth, height=0.45\textheight]{images/usecase.png}
    \caption{Diagram užití}
    \label{fig:usecase}
\end{figure}

Typickým místem pro nasazení distribuovaného zpracování událostí je analýza síťové komunikace. To je také místo, kde bude DEM nasazen.

Nejčastější případ, je ten, že přes jeden hlavní uzel probíhá většina komunikace. Podobně je tomu i v softwaru. Aplikační server zpracovává všechny klientské požadavky. Takový uzel je zdrojem dat, která chceme analyzovat. Vytváří sekvenční proud dat, který můžeme vhodně distribuovat do clusteru. Ten jej zpracovává.

Problém nastane, když je množství produkovaných dat větší než je kapacita analyzujícího (analyzujících) počítačů. V takovém případě můžeme přidat výpočetní sílu nebo zvolit úplně jiný přístup k datové analýze.

\section{Vstupy a výstupy}
Uvažujme situaci, kdy necháme na síťovém uzlu aby analyzoval běžně známe hrozby. Taková zařízení jsou na trhu běžně dostupná. A zbytek analýzy bude probíhat až na uzlech v rámci sítě. V modelové situaci útočník obejde firewall a na koncových zařízeních v síti začnou vznikat anomálie. Za normální situace by se takový útok neodhalil, protože na koncových zařízeních neběží žádná detekce. Často to ani není prakticky možné, protože kdyby počítače odesílaly všechen provoz do clusteru na analýzu, byla by to ještě větší zátěž než, kdyby to dělal hlavní síťový prvek. Cílem této práce je tak vytvořit řešení, které bude možno nasadit přímo na koncová zařízení a provádět analýzu tam. Hrubou představu znázorňuje obrázek \ref{fig:cloud-comparison}

\begin{figure}[H]
	\centering
    \includegraphics[width=0.8\textwidth, height=0.55\textheight]{images/cloud-comparison.png}
    \caption{Srovnání přístupu zasílání dat do cloudu (v levo) a vytvoření cloudu přímo na koncových zařízeních (v pravo)}
    \label{fig:cloud-comparison}
\end{figure}

Vstupem jsou data zaznamenána na každém stroji připojeném do \textit{DEM}. Formát, množství a povaha dat je pak určena konkrétní situací, která je potřeba sledovat. Pro účely této práce jsou data naivně generována aby vytvořila simulaci síťového útoku. Detailní popis je v kapitole~\ref{sec:udalosti-v-systemu}

Výstupem by mělo být upozornění na nestandardní situaci v části nebo celém systému. Formát výstupu DEM je opět individuální vzhledem k situaci. Zjištěné výsledky mohou být ukládány ve formě logů (tak je to vyřešeno v této práci), odesílána do centrálního dohledu nebo ukládána do databáze.

Do DEM bude možno nasadit pravidla na detekci vzorů událostí. Tato pravidla mohou být omezena časovou platností a nasazena na analýzu pouze určitého množství uzlů.
\chapter{Návrh}
Tato kapitola postupně popisuje jak budou reálně splněny požadavky na systém uvedené v analýze. Stěžejní část kapitoly je volba technologií. U každé zvolené technologie je její popis a jak bude použita ve výsledném řešení.

\section{Technologie}
Tato kapitola podkapitola jednotlivé technologie, které jsou použity při implementaci algoritmu. Na konci každé subsekce je popis toho jak konkrétně je technologie použita v mém řešení.

\subsection{Apache Maven}
Apache Maven je nástroj pro správu, řízení a automatizaci sestavování aplikací (angl. build). Maven sám nemá žádné uživatelské rozhraní a běží pouze na příkazové řádce. Jeho účelem je usnadnit práci vývojáři tím, že definuje jednotný proces sestavení. \ref{bib_4} Také definuje strukturu aplikace, protože jednotlivé typy souborů hledá v určitých balíčcích. Například spustitelné Java soubory by měly být v adresáři \textit{src/maven/java}.

Konfigurační soubor Mavenu je \textit{pom.xml}, ve kterém jsou uvedeny zásuvné moduly (pluginy), podle kterých Maven pozná, co má dělat. Také je zde seznam závislostí na externí knihovny, které Maven dokáže stáhnout. Při použití Mavenu je sestavení programu otázkou jen jednoho příkazu (\textit{mvn clean install}).

\subsection*{Použití}
Kromě definování závislostí je Maven v projektu použit na vytvoření modulů. Moduly jsou celkem čtyři a jsou navrženy tak, aby názvem i logikou odpovídaly účelu a nepřesahovaly své určení. Jsou to:
\begin{itemize}
  \item Producer -- slouží pro generování dat a jejich posílání do Kafky. Data jsou generována v určitých časových intervalech a jejich struktura je přesně daná. Syntax a sémantika vzorových dat je popsána v kapitole \ref{sec:udalosti-v-systemu}. Při reálném použití by byl tento modul přepsán nebo nahrazen za takový, který bude reálná data číst z nějakého systémového nebo aplikačního logu.
  \item Consumer -- tento modul čte data z Kafky a analyzuje je za pomocí nástroje Esper \ref{sec:esper}. Události, které Esper vyhodnotí slouží v DEM jako řídící zprávy pro přechod do dalšího stavu. Případně jsou události pouze zapsány do logu.
  \item MainApp -- modul obsahuje spustitelnou třídu a je tak vstupním bodem programu. Také se zde zpracovávají všechny řídící události ze ZooKeeperu \ref{sec:zookeeper} a rozhoduje se jaká vlákna (konzument nebo producent) se mají vytvořit nebo zastavit.
  \item AppData -- modul obsahuje několik výčtových typů, které jsou společné v celé aplikaci a jednu singleton \footnote{Singleton neboli jedináček je návrhový vzor, který je využívaný, když je potřeba mít pouze jednu instanci dané třídy.} třídu, která drží některá řídící data. Například ip adresu počítače. Tato data mají k dispozici všechny moduly.
\end{itemize}
Protože je veškerá komunikace řízena událostmi a zasíláním zpráv, moduly jsou na sobě relativně nezávislé a v případě potřeby je možné je zaměnit za jiné. 

\subsection{Apache Kafka}
Apache Kafka je systém pro zasílání zpráv. [\ref{bib_5}] Klastr Kafky může být rozdělený mezi několik počítačů, každý nazýváme \textit{broker}. Základem Kafky je fronta zpráv. Ta je reprezentována tématem (angl. topic) respektive přepážkou (angl. partition). Při vytváření tématu udáváme kromě jejího jména, také kolikrát se má replikovat mezi \textit{brokery} a počet přepážek. Přepážka je menší jednotka než téma. Každé téma může být replikováno mezi brokery.

\subsection*{Konzument a producent}

Do kafky data zapisují \textit{producenti} a na druhé straně z ní data čtou \textit{konzumenti} (angl. producer and consumer). Zapisování dat producentem je přímočaré. Producent rozhoduje do kterého tématu či přepážky se má zpráva zapsat. Zprávy jsou ukládány do fronty, tedy způsobem FIFO \footnote{FIFO -- první zapsán, první přečten (angl. first in first out)}. Čtení zpráv závisí na aktuálním stavu. Konzumenty je možné seskupovat do skupin a podle toho se pak rozlišuje způsob čtení zpráv na "queuing" a "publish-subscribe". V modelu "queue" je zpráva poslána vždy jednomu z konzumentů. Naopak v modelu "publish-subscribe" je každá zpráva poslána všem konzumentům. V dokumentaci Kafky se říká [\ref{bib_5}]:
\begin{itemize}
  \item Pokud jsou všichni konzumenti ve stejné skupině, pak Kafka funguje v modelu "queue".
  \item Pokud je každý konzument v jiné skupině, pak je Kafka v modelu "publish-subscribe". Všechny zprávy jsou distribuovány všem konzumentům \footnote{Broadcast}.
\end{itemize}

\begin{figure}[H]
	\centering
    \includegraphics[width=0.65\textwidth, height=0.45\textheight]{images/kafka.png}
    \caption{Znázornění základního schématu Kafky}
    \label{fig:kafka}
\end{figure}

\subsection*{Garance}
Kafka poskytuje následující seznam garancí:
\begin{itemize}
  \item Zprávy poslané do určitého tématu budou seřazeny v pořadí v jakém byly odeslány. Například pokud je zpráva \textit{M1} odeslána producentem dříve než zpráva \textit{M2}, pak Kafka zaručuje, že bude mít zpráva \textit{M1} menší offset a bude v logu zobrazena dříve než \textit{M2}.
  \item Konzument vidí zprávy v takovém pořadí, v jakém byly uloženy do logu.
  \item Pro téma s faktorem replikování \textit{N} (bude replikováno mezi \textit{N} brokerů), Kafka zaručuje zachování dat až pro \textit{N-1} vypadlých serverů.
\end{itemize}

\subsection*{Použití}
Jak už bylo řečeno dříve analýza událostí bude probíhat na počítačích, které data produkují. V navrhovaném řešení jsem nezaznamenal potřebu dělit témata na příčky (partition). Také Kafka není distribuovaná do několika brokerů a je spuštěna pouze na jenom stroji. Distribuci bych nakonfiguroval až v případě produkčního nasazení pro prevenci výpadků. Na každém počítači běží nejméně jeden producent a nejvýše jeden konzument. Jednotlivá témata jsou pojmenována podle ip adres počítačů. Konkrétně při iniciálním spuštění je vytvořen jeden konzument a počet producentů je roven počtu počítačů. Viz obrázek \ref{fig:kafka-impl}

\begin{figure}[H]
	\centering
    \includegraphics[width=0.8\textwidth, height=0.45\textheight]{images/kafka-impl.png}
    \caption{Struktura Kafky při iniciálním spuštění}
    \label{fig:kafka-impl}
\end{figure}

\newpage
\subsection{Apache ZooKeeper}
\label{sec:zookeeper}
ZooKeeper je další z rodiny "open-source" Apache technologií. Je to centralizovaná služba pro správu konfiguračních dat, pojmenování a poskytování synchronizace distribuovaných uzlů. [\ref{bib_7}]

ZooKeeper je navržen, tak aby jej bylo jednoduché použít. Je napsán v Javě a poskytuje konektory pro Javu a pro C. Struktura datového modelu je podobná stromovému uspořádání souborového systému. Datový model ZooKeeperu je sestaven z uzlů zvaných \textit{znodes}. Na rozdíl od klasického souborového systému, který je navržen pro dlouhodobé ukládání dat, ZooKeeper data drží v paměti, a tak může dosahovat nízkého zpoždění a vysoké propustnosti. Pro ilustraci, uvažujme jednoduchý příklad: Každý znode může obsahovat data (až do limitu 1MB). V takovém případě znode reprezentuje soubor (řekněme textový) v souborovém systému. V ZooKeeperu může mít každý uzel nula až N potomků. Pak znode vystupuje obdobně jako složka v souborovém systému. Každý znode může zároveň obsahovat data a mít potomky.

\subsection*{Garance}
Obdobně jako Kafka a naprostá většina distribuovaných systémů, musí i ZooKeeper poskytovat určité garance běhu v distribuovaném prostředí.

\begin{itemize}
  \item Sekvenční konzistence -- změny na uzlu jsou aplikovány v takovém pořadí v jakém byly odeslány (modifikace dat, odebrání nebo přidání potomka, apod).
  \item Atomicita -- změny jsou úspěšně aplikovány úplně nebo neprovedeny vůbec. Neexistuje žádný mezistav.
  \item Spolehlivost -- Jakmile je změna aplikována, je stav uzlu garantován. Nemění se až do doby další změny.
  \item Časová konzistence -- Stav systému je po uplynutí definovaného času vždy aktuální.
\end{itemize}

\subsection*{API}
ZooKeeper nabízí uživateli (programátorovi) velice jednoduché rozhraní, pro manipulaci s jednotlivými uzly. Sestává se z těchto operací:
\begin{itemize}
  \item Vytvoření (create)
  \item Smazání (delete)
  \item Kontrola existence uzlu (exists)
  \item Získání dat (get data)
  \item Zapsání dat (set data)
  \item Získání všech potomků daného uzlu (get children)
  \item Ukazatel dokončení synchronizace dat (sync)
\end{itemize}

Kromě operace \textit{sync} jsou v této práci použity všechny.

\subsection*{Pozorovatelé}
Pozorovatelé \footnote{Z anglického slova \textit{Watches}. Jde o konkrétní implementaci návrhového vzoru "observable". [\ref{bib_8}]} jsou nedílnou součástí téměř každého událostmi řízeného systému. Stejně tak, je tomu u ZooKeeperu. Na znode je možné zaregistrovat dva druhy pozorovatelů:

\begin{itemize}
  \item Datový pozorovatel -- změní stav, když jsou změněna data v uzlu. Tzn někdo zavolal operaci "zapsání dat". Změna stavu obsahuje nově nastavená data
  \item Pozorovatel potomků -- změní stav, když nastane změna v některém z potomků daného uzlu. Událost obsahuje, mimo jiné, informaci o typu změny (smazání, vytvoření, zápis dat, ztráta konektivity) a identifikaci potomka. 
\end{itemize}

\subsection*{Apache Curator}
Aplikační rámec \textit{Curator}	je nástroj vytvořený společností Neflix pro jednodušší práci se ZooKeeperem. Rozhraní ZooKeeperu se potýká s několika problémy, jako je například nedostatečné ošetření výpadků konektivity nebo selhání operace. Proto byl navržen \textit{Curator}, který se osvědčil a později přešel pod licenci \textit{Apache}. Poskytuje následující benefity:

\begin{itemize}
  \item Komplexnější rozhraní pro jednodušší práci se ZooKeeperem. \ref{code:curator}
  \item Automatické připojení na instanci ZooKeeperu a automatické opravy výpadků.
  \item Kompletní a dobře otestovaná implementace některých složitějších operací.
\end{itemize}

\begin{lstlisting}[label=code:curator,caption={Demonstrace jednoduchého použití aplikačního rámce Curator, na smazání uzlu \textit{zkNode1} a všech jeho potomků.},language=Java]
curatorFramework.delete()
   .guaranteed()
   .deletingChildrenIfNeeded()
   .forPath("/zkNode1");
\end{lstlisting}
 
\subsection*{Použití}
ZooKeeper je použit pro řízení běhu celého procesu DEM. Jeho hlavní úlohou je distribuce řídících dat mezi jednotlivými výpočetními jednotkami. Druhou funkcí, která logicky vychází ze stromové struktury datového modelu, je reflexe aktuálního stavu aplikace.

Je důležité zmínit, že cesta ve stromové struktuře je určena jednoznačným textovým identifikátorem. Jednotlivé uzly jsou pak odděleny lomítkem. Na obrázku \ref{fig:zookeeper-impl} můžeme vidět strukturu uzlů, při iniciálním spuštění DEM. Příklad identifikátoru prvního uzlu z druhé vrstvy je \textit{"/root/ip1/ip1"}, druhého uzlu z první vrstvy \textit{"/root/ip2"}, atd.

Obrázek \ref{fig:zookeeper-impl} dále znázorňuje logickou strukturu DEM. První vrstva reprezentuje konzumenty a druhá vrstva producenty. Jinak řečeno "kdo komu posílá data". Podstatné je, uvědomit si, že strom zobrazuje pouze virtuální stav. Aplikace jako taková běží na daném stroji vždy jen jednou a strom pak reprezentuje spíše množství běžících vláken a jejich úlohu. Jak je vidět z obrázku \ref{fig:zookeeper-impl}, v DEM existují 4 producenti (jeden na každém fyzickém stroji) a jeden konzument (fyzický stroj s \textit{ip1}). To odpovídá stavu Kafky z obrázku \ref{fig:kafka-impl}.

Výhody stromové struktury jsou jasné. U každého uzlu se dá zjistit jaké má potomky (které stroje posílají data a kam). Změna cíle, kam má stroj posílat data, je na úrovni rozhraní triviální. Stačí přesunout uzel v druhé vrstvě pod jiného rodiče.

\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth, height=0.22\textheight]{images/zookeeper-impl.png}
    \caption{Stromová struktura uzlů v Zookeeperu při iniciálním spuštění.}
    \label{fig:zookeeper-impl}
\end{figure}

\newpage
\subsection{Esper}
\label{sec:esper}
TODO - dopsat

\section{Sumarizace}
Kapitola obsahuje přehlednou tabulku, která konkrétně ukazuje která technologie je použita při implementaci daného požadavku z analýzy.

\begin{table}[H]
  \centering
  \begin{tabularx}{\textwidth}{lllX}
    \toprule
    Požadavek & Technologie \\
    \midrule
    Posílání zpráv mezi stroji & Kafka \\
    Libovolný počet připojených uzlů & ZooKeeper + Kafka \\
    Nasazení nového pravidla & ZooKeeper \\
    Definování chování jednotlivých strojů & ZooKeeper \\
    Vytvořit nebo rozpustit skupinu strojů & ZooKeeper \\
    Nalezení určitého vzoru (pattern) v datech & Esper \\
    Propojit technologie do funkčního celku & Java + Maven \\
    \bottomrule
  \end{tabularx}
  \caption{Splnění požadavků na systém}
  \label{tab:fulfill-usecases}
\end{table}

\section{Události v systému}
\label{sec:udalosti-v-systemu}
Povaha a struktura vyhodnocovaných dat je neopomenutelnou součástí každého systému, tedy i tohoto. Pro potřeby analýzy zavedeme dva druhy událostí, \textbf{hrubozrné} a \textbf{jemnozrné}. Hrubozrné jsou události, které nenastávají příliš často, ale mají v systému důležitý význam. Jemnozrné naopak.

Jak je nastíněno v kapitole \label{sec:analysis}, budeme se zabývat analýzou síťové komunikace. Základem je zde samozřejmě proud paketů. Příchozí pakety mohou mimo jiné znamenat pro daný stoj bezpečnostní hrozbu. Například při útoku \textit{SYN flood} je restart (kolaps) stroje způsoben zahlcením pakety s příznakem \textit{SYN}. Zde můžeme za hrubozrnou událost považovat signalizaci restartu stroje. Jemnozrné události jsou pak jednotlivé pakety.

Principem analýzy je identifikace strojů s výskytem stejných hrubozrných událostí a pustit na nich analýzu jemnozrných událostí, která ma za cíl odhalit příčinu.
 
\subsection*{Hrubozrnné}
Hrubozrné události mají komplexní povahu. Jsou tedy výsledkem nějakého složitějšího procesu. Ve výše uvedeném příkladě šlo o restart počítače způsobený cíleným útokem. Jiným příkladem může být chybová zpráva v aplikaci (angl. error log). Pokud je aplikace zasažena \textit{DoS} útokem, pak je hrubozrnou událostí její nedostupnost. V DEM jsou hrubozrné události reprezentovány štítkem \textbf{LEVEL1}.
 
\subsection*{Jemnozrnné}
Tento druh událostí se vyskytuje běžně a sama o sobě nemá událost prakticky žádný význam. Například jeden paket s s příznakem \textit{SYN} se v síťové komunikaci objevuje běžně. V DEM jsou hrubozrné události reprezentovány štítkem \textbf{LEVEL2}.

\chapter{Nasazení}
Kapitola je jádrem této práce. Popisuje implementaci a fungování DEM.

\section{Konfigurace}
\section{Implementace}
Pro implementaci byla zvolena Java (konkrétně ve verzi 1.8), protože všechny použité technologie mají dobrá API pro Javu a většina příkladů je právě v Javě. Dalším důvodem je také to, že Java se dobře hodí pro běh aplikací tohoto druhu, protože má dobrou práci s vlákny. Posledním, méně důležitým, důvodem je popularita Javy a snadná čitelnost kódu.
\subsection*{Architektura aplikace}
Je popsána v kapitole Maven. Hodilo by se sem ale ještě něco dopsat. 
\subsection{Iniciální spuštění}
\subsection{Přechody mezi stavy}
Jedna z nejdůležitějších kapitol, která ukazuje co způsobí, že aplikace začne vyhodnocovat jemnozrnné události. Počínaje tím, že Esper vyhodnotí proud událostí a emituje ep-událost. Dále přes zpracování ep-události, nastavení příslušných dat jednotlivým zk-uzlům v zk-stromě, či modifikaci zk-stromu. Až po ukončení zpracovávání jemnozrnný událostí a návrat k iniciálnímu stavu.

Bude zde také zmíněno dynamické nasazování nových ep pravidel. To by se dalo shrnout pod nadpis "ovládání clusteru z venčí" - řešeno přes nastavování dat jednotlivým uzlům v zookeeperu.

\subsection{Esper pravidla}
Mini kapitola, kterou bych věnoval použitým esper pravidlům.
\section{Testování}

\begin{center}
\begin{minipage}[H]{.6\linewidth}
	\begin{mylisting}
	{
		level: "LEVEL1 / LEVEL2",
		source: <zk-path>
	}
	\end{mylisting}
	\captionof{figure}{První ukázka}
	\label{fig:data-example-1} 
\end{minipage}
\end{center}

\begin{center}
\begin{minipage}[H]{.65\linewidth}
	\begin{mylisting}
	{
		level: "LEVEL1 / LEVEL2",
		source: <zk-path>,
		msg: "info textual message",
		flag: "SYN",
		size: 10,
		port: 80
	}
	\end{mylisting}
	\captionof{figure}{Druhá ukázka}
	\label{fig:data-example-2} 
\end{minipage}
\end{center}

\section{Demo}
Nějaké print screeny. Jednoduše ukázka běhu programu.
\section{Známá omezení}
Diskuse nedostatků nebo možných vylepšení výše navrženého řešení. 
\begin{itemize}
	\item Momentální nemožnost spustit více consumerů na jednom stroji.
	\item Velmi náročný monitoring a spouštění jednotlivých uzlů.
	\item Zatím nevím jak je to s dynamickým přidáváním nových uzlů do hierarchie.
	\item Nejsou vůbec otestovány výpadky některých uzlů. Zookeeper to zvládne, kafka také, ale co se stane s virtuálním zk-tree v aplikaci?
\end{itemize}

\chapter{Závěr}
Závěr bude v tomto případě obsahovat obšírnější zhodnocení toho jak se povedlo splnit zadání. Že výsledkem práce je navržené řešení za použití kafky, zk, esperu, Javy.


\begin{thebibliography}{99}
\bibitem
LLUCKHAM, David. \textit{The Power of Events: An Introduction to Complex
Event Processing in Distributed Enterprise Systems.} Addison-Wesley Professional, 2002. ISBN 978-0-201-72789-0. \label{bib_1}

\bibitem
CCOULOURIS, George F. \textit{Distributed systems: concepts and design}. 5th ed. Boston: Addison-Wesley, c2012. ISBN 01-321-4301-1. \label{bib_2}
%% Dostupné z: \url{https://azmuri.files.wordpress.com/2013/09/george-coulouris-distributed-systems-concepts-and-design-5th-edition.pdf}

\bibitem
KKAMBURUGAMUVE, Supun; FOX, Geoffrey; LEAKE, David and QIU, Judy. \textit{Survey of Distributed Stream Processing for Large Stream Sources}. Technical report, 2013. [online]. Dostupné z: \url{http://grids.ucs.indiana.edu/ptliupages/publications/survey_stream_processing.pdf} \label{bib_3}

\bibitem
AApache Maven [online]. Dostupné z: \url{http://maven.apache.org} \label{bib_4}

\bibitem
AApache Kafka [online]. Dostupné z: \url{http://kafka.apache.org} \label{bib_5}

\bibitem
OOfficial Google documentation  [online]. Dostupné z: \url{https://support.google.com/analytics/answer/1662518?hl=en&ref_topic=3205717} \label{bib_6}

\bibitem
AApache ZooKeeper [online]. Dostupné z: \url{https://zookeeper.apache.org/} \label{bib_7}

\bibitem
GGAMMA, Erich, Richard HELM, Ralph JOHNSON a John VLISSIDES. GANG OF FOUR. \textit{Design Patterns: Elements of Reusable Object-Oriented Software}. Addison-Wesley, 1994. ISBN 0-201-63361-2 \label{bib_8}

\bibitem
AApache Curator [online]. Dostupné z: \url{http://curator.apache.org/index.html} \label{bib_9}

\end{thebibliography}
\appendix %% Start the appendices.

\end{document}
